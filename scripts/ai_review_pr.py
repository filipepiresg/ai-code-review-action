"""
ü§ñ AI Code Review Script
========================

Este script realiza an√°lise autom√°tica de c√≥digo usando IA (OpenAI GPT ou Anthropic Claude).
Ele analisa arquivos modificados em Pull Requests e publica feedback automaticamente.

Funcionalidades:
- Suporte a m√∫ltiplas linguagens de programa√ß√£o
- An√°lise de seguran√ßa e vulnerabilidades
- Detec√ß√£o de m√°s pr√°ticas e sugest√µes de melhoria
- Sistema de ignore configur√°vel (regex e arquivo)
- Limite configur√°vel de arquivos analisados
- Chunking autom√°tico para arquivos grandes
- Sistema de cache autom√°tico baseado em GitHub Artifacts

Autor: Filipe Pires
Vers√£o: 1.0.0
"""

import hashlib
import json
import os
import pathspec
import re
import sys
import textwrap

# ===============================
# üîß CONFIGURA√á√ïES INICIAIS
# ===============================
# Carrega vari√°veis de ambiente necess√°rias para execu√ß√£o
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")      # Chave da API OpenAI
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")      # Chave da API Anthropic Claude
MODEL_NAME = os.getenv("MODEL_NAME", "gpt-5")     # Modelo de IA a ser usado

# Configura√ß√µes do GitHub
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")          # Token para intera√ß√£o com GitHub API
REPO = os.getenv("GITHUB_REPOSITORY")             # Reposit√≥rio no formato owner/repo
PR_NUMBER = os.getenv("GITHUB_PR_NUMBER")         # N√∫mero do Pull Request

# Configura√ß√µes de an√°lise
ANALYZE_LIMIT = int(os.getenv("ANALYZE_LIMIT", "10"))                     # M√°ximo de arquivos a analisar
IGNORE_FILE_CONTENT = os.getenv("IGNORE_FILE_CONTENT", "")                # Padr√µes regex para ignorar
IGNORE_FILE_PATH = os.getenv("IGNORE_FILE_PATH") or ".ai-review-ignore"   # Caminho do arquivo de ignore
GUIDELINES_PATH = os.getenv("GUIDELINES_PATH")

# Extens√µes de arquivos suportadas para an√°lise
SUPPORTED_EXTENSIONS = (
    ".py", ".js", ".ts", ".tsx", ".jsx", ".java", ".cs", ".php",
    ".rb", ".go", ".swift", ".kt", ".rs"
)

# Diret√≥rio base do cache persistente
# Sistema autom√°tico baseado em GitHub Artifacts
# Cache √© baixado/salvo automaticamente pela action
WORKSPACE = os.getenv("GITHUB_WORKSPACE", os.getcwd())
raw_cache_dir = os.getenv("CACHE_DIR", "cache")
CACHE_DIR = os.path.join(WORKSPACE, raw_cache_dir, "ai_review_cache")
os.makedirs(CACHE_DIR, exist_ok=True)

# ===============================
# ‚öôÔ∏è FUN√á√ïES AUXILIARES
# ===============================

def log(msg):
    """
    Exibe mensagens de log com prefixo identificador.
    
    Args:
        msg (str): Mensagem a ser exibida
    """
    print(f"[AI-Review] {msg}")

def shorten_multiline(text, width, placeholder=' [...]'):
    """
    Encurta um texto de m√∫ltiplas linhas para que o texto total caiba em 'width',
    preservando as quebras de linha existentes.

    Args:
        text (str): O texto de entrada.
        width (int): O n√∫mero m√°ximo de caracteres que o texto de sa√≠da pode ter.
        placeholder (str): O espa√ßo reservado para indicar que o texto foi encurtado.

    Returns:
        str: O texto encurtado.
    """
    if not isinstance(text, str):
        raise TypeError("O argumento 'text' deve ser uma string.")

    if len(text) <= width:
        return text

    # Trata as quebras de linha existentes
    lines = text.splitlines()
    output = []
    current_length = 0

    # Adiciona a primeira linha (ou parte dela) at√© o limite
    # e continua com as demais linhas se houver espa√ßo
    for line in lines:
        if current_length + len(line) <= width - len(placeholder):
            output.append(line)
            current_length += len(line) + 1  # +1 para a quebra de linha
        else:
            remaining_width = width - current_length - len(placeholder)
            if remaining_width > 0:
                output.append(line[:remaining_width])
            # Adiciona o espa√ßo reservado e interrompe
            output.append(placeholder)
            break
    
    return "\n".join(output)
    
def get_file_hash(content: str):
    """Gera hash √∫nico de um arquivo (SHA-256)."""
    return hashlib.sha256(content.encode("utf-8")).hexdigest()

def load_cache(file_hash: str):
    """Carrega resultado de cache se existir."""
    path = os.path.join(CACHE_DIR, f"{file_hash}.json")
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return None

def save_cache(file_hash: str, data: dict):
    """Salva resultado da an√°lise em cache."""
    path = os.path.join(CACHE_DIR, f"{file_hash}.json")
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    log(f" ‚îî‚îÄ‚îÄ ‚ö° Cache {file_hash} em: {path}")

def load_ignore_patterns():
    """
    Carrega padr√µes de ignore de um arquivo (formato .gitignore).
    
    Returns:
        list: Lista de padr√µes glob para ignorar arquivos
    """
    patterns = []
    if IGNORE_FILE_PATH:
        ignore_path = os.path.join(WORKSPACE, IGNORE_FILE_PATH)
        if os.path.exists(ignore_path):
            log(f"üìÑ Carregando padr√µes de ignore: {ignore_path}")
            with open(ignore_path, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith("#"):
                        continue
                    patterns.append(line)
        else:
            log(f"‚ö†Ô∏è Arquivo de ignore n√£o encontrado: {ignore_path}")
    separator_comma_space = ", "
    log(f" ‚îî‚îÄ‚îÄ Arquivo regex ignoradas: {separator_comma_space.join(patterns)}")
    return patterns

def compile_regex_patterns():
    """
    Compila padr√µes regex passados via vari√°vel de ambiente.
    
    Returns:
        list: Lista de objetos regex compilados para ignorar arquivos
    """
    regex_list = []
    if IGNORE_FILE_CONTENT.strip():
        for line in IGNORE_FILE_CONTENT.strip().splitlines():
            pattern = line.strip()
            if not pattern:
                continue
            try:
                regex_list.append(re.compile(pattern))
            except re.error as e:
                log(f"‚ö†Ô∏è Regex inv√°lida ignorada: {pattern} ({e})")
    separator_comma_space = ", "
    log(f" ‚îî‚îÄ‚îÄ Regex ignoradas: {separator_comma_space.join(regex_list)}")
    return regex_list

def should_ignore(filename, ignore_globs, ignore_regex):
    """
    Verifica se um arquivo deve ser ignorado baseado nos padr√µes configurados.
    
    Args:
        filename (str): Caminho do arquivo a verificar
        ignore_globs (list): Lista de padr√µes glob para ignorar
        ignore_regex (list): Lista de regex compiladas para ignorar
        
    Returns:
        bool: True se o arquivo deve ser ignorado, False caso contr√°rio
    """
    # Cria o objeto pathspec
    spec_globs = pathspec.PathSpec.from_lines("gitwildmatch", ignore_globs)
    spec_regex = pathspec.PathSpec.from_lines("gitwildmatch", ignore_regex)
    if spec_globs.match_file(filename) or spec_regex.match_file(filename):
        return True
    return False

def load_guidelines():
    """
    1. Tenta carregar diretrizes do reposit√≥rio do usu√°rio (WORKSPACE)
    2. Se n√£o existir, tenta carregar do reposit√≥rio da Action (GITHUB_ACTION_PATH)
    """
    # Caminho no reposit√≥rio onde a Action est√° sendo executada (projeto do usu√°rio)
    workspace = os.getenv("GITHUB_WORKSPACE", os.getcwd())
    user_guidelines = os.path.join(workspace, "knowledge", "ai-review-guidelines.md")

    # 1Ô∏è‚É£ Verifica no reposit√≥rio do usu√°rio (workflow)
    if os.path.exists(user_guidelines):
        log(f"üìò Usando diretrizes do reposit√≥rio do usu√°rio: {user_guidelines}")
        with open(user_guidelines, "r", encoding="utf-8") as f:
            return f.read()

    # Caminho no reposit√≥rio da pr√≥pria Action
    action_path = os.getenv("GITHUB_ACTION_PATH")
    action_guidelines = None
    if action_path:
        action_guidelines = os.path.join(action_path, "knowledge", "ai-review-guidelines.md")

    # 2Ô∏è‚É£ Se n√£o existir, verifica no reposit√≥rio da Action
    if action_guidelines and os.path.exists(action_guidelines):
        log(f"üìó Usando diretrizes padr√£o da Action: {action_guidelines}")
        with open(action_guidelines, "r", encoding="utf-8") as f:
            return f.read()

    # 3Ô∏è‚É£ Se nada existir, retorna vazio
    log("‚ö†Ô∏è Nenhum arquivo de diretrizes encontrado (workspace nem action)")
    return ""

def get_pull_request():
    """
    Obt√©m o objeto Pull Request do GitHub.
    
    Returns:
        github.PullRequest.PullRequest: Objeto do PR para an√°lise
    """
    from github import Auth, Github

    auth = Auth.Token(GITHUB_TOKEN)
    gh = Github(auth=auth)
    repo = gh.get_repo(REPO)
    return repo.get_pull(int(PR_NUMBER))

def get_file_content(filename, repo):
    """
    Obt√©m o conte√∫do de um arquivo do reposit√≥rio.
    
    Args:
        filename (str): Caminho do arquivo
        repo: Objeto do reposit√≥rio GitHub
        
    Returns:
        str: Conte√∫do do arquivo em UTF-8, ou string vazia em caso de erro
    """
    try:
        return repo.get_contents(filename).decoded_content.decode("utf-8")
    except Exception:
        return ""

def chunk_code(content, max_chars=8000):
    """
    Divide c√≥digo em blocos menores para evitar limite de tokens das APIs.
    
    Args:
        content (str): Conte√∫do do c√≥digo a ser dividido
        max_chars (int): N√∫mero m√°ximo de caracteres por chunk
        
    Returns:
        list: Lista de strings contendo chunks do c√≥digo
    """
    lines = content.splitlines()
    chunks, current, size = [], [], 0
    for line in lines:
        size += len(line)
        current.append(line)
        if size >= max_chars:
            chunks.append("\n".join(current))
            current, size = [], 0
    if current:
        chunks.append("\n".join(current))
    return chunks

# ===============================
# ü§ñ CLIENTE DE IA DIN√ÇMICO
# ===============================

def call_openai(prompt, code_chunk):
    """
    Chama a API da OpenAI para an√°lise de c√≥digo.
    
    Args:
        prompt (str): Prompt de an√°lise para o modelo
        code_chunk (str): Bloco de c√≥digo a ser analisado
        
    Returns:
        str: Resposta do modelo OpenAI com an√°lise do c√≥digo
    """
    import openai
    openai.api_key = OPENAI_API_KEY
    system_prompt = build_system_prompt()
    response = openai.chat.completions.create(
        model=MODEL_NAME,
        temperature=0.3,  # Baixa temperatura para respostas mais consistentes
        messages=[
            {"role": "system", "content": f"{prompt}"},
            {"role": "user", "content": f"{code_chunk}"}
        ],
    )
    return response.choices[0].message.content.strip()

def call_claude(prompt, code_chunk):
    """
    Chama a API da Anthropic Claude para an√°lise de c√≥digo.
    
    Args:
        prompt (str): Prompt de an√°lise para o modelo
        code_chunk (str): Bloco de c√≥digo a ser analisado
        
    Returns:
        str: Resposta do modelo Claude com an√°lise do c√≥digo
    """
    from anthropic import Anthropic
    client = Anthropic(api_key=CLAUDE_API_KEY)
    response = client.messages.create(
        model=MODEL_NAME if MODEL_NAME.startswith("claude") else 'claude-sonnet-4-5',
        max_tokens=2000,  # Limite de tokens para resposta
        temperature=0.3,
        messages=[
            {"role": "user", "content": f"{prompt}\n\n{code_chunk}"}
        ]
    )
    return response.content[0].text.strip()

def analyze_code(filename, content):
    """
    Analisa c√≥digo usando IA (OpenAI ou Claude) com foco em seguran√ßa e boas pr√°ticas.
    
    Esta fun√ß√£o divide o c√≥digo em chunks para evitar limites de tokens e analisa
    cada parte separadamente, focando em:
    - Vulnerabilidades de seguran√ßa (SQLi, XSS, etc.)
    - Viola√ß√µes de boas pr√°ticas
    - Sugest√µes de melhoria
    - Observa√ß√µes gerais sobre qualidade
    
    Args:
        filename (str): Nome do arquivo sendo analisado
        content (str): Conte√∫do do c√≥digo a ser analisado
        
    Returns:
        str: Relat√≥rio de an√°lise formatado em Markdown
    """
    file_hash = get_file_hash(content)
    cached = load_cache(file_hash)
    if cached is not None:
        log(f" ‚îî‚îÄ‚îÄ ‚ö° Arquivo cacheado")
        return cached["analysis"]

    guidelines = load_guidelines()
    prompt = f"{guidelines}\n\nAgora analise o arquivo `{filename}` com base nessas diretrizes."
    try:
        chunks = chunk_code(content)
        report = ""
        log(f" ‚îî‚îÄ‚îÄ üß† Arquivo sem cache")
        for chunk in chunks:
            if OPENAI_API_KEY:
                report += call_openai(prompt, chunk) + "\n\n"
            elif CLAUDE_API_KEY:
                report += call_claude(prompt, chunk) + "\n\n"
            else:
                raise ValueError("Nenhuma chave de LLM foi fornecida (openap_api_key ou claude_api_key).")
                
        save_cache(file_hash, {"filename": filename, "analysis": report})
        return report
    except Exception as e:
        log(f"‚ö†Ô∏è Erro ao analisar {filename}: {str(e)}")
        return None

def post_comment(pr, body):
    """
    Publica coment√°rio no Pull Request com o relat√≥rio de an√°lise.
    
    Args:
        pr: Objeto do Pull Request do GitHub
        body (str): Conte√∫do do coment√°rio a ser publicado
    """
    try:
        pr.create_issue_comment(body)
        log("üí¨ Coment√°rio publicado no PR com sucesso.")
    except Exception as e:
        log(f"‚ö†Ô∏è Falha ao comentar no PR: {str(e)}")

# ===============================
# üöÄ EXECU√á√ÉO PRINCIPAL
# ===============================

if __name__ == "__main__":
    """
    Fun√ß√£o principal que executa o processo completo de an√°lise de c√≥digo.
    
    Fluxo de execu√ß√£o:
    1. Valida√ß√£o de vari√°veis de ambiente
    2. Carregamento de padr√µes de ignore
    3. Obten√ß√£o do Pull Request
    4. Filtragem de arquivos modificados
    5. An√°lise de cada arquivo com IA
    6. Publica√ß√£o do relat√≥rio no PR
    """
    
    # ===============================================
    # üîç DEBUG E VALIDA√á√ÉO INICIAL
    # ===============================================
    print("======== DEBUG VARS: ========")
    DEBUG_VARS = (
        "GITHUB_WORKSPACE", "GITHUB_REPOSITORY", "GITHUB_PR_NUMBER",
        "OPENAI_API_KEY", "CLAUDE_API_KEY", "MODEL_NAME", "ANALYZE_LIMIT",
        "IGNORE_FILE_CONTENT", "IGNORE_FILE_PATH", "CACHE_DIR",
        "GUIDELINES_PATH"
    )
    for var in DEBUG_VARS:
        print(f" - {var}={os.getenv(var)}")
    print("=============================")

    # Valida√ß√£o de vari√°veis obrigat√≥rias do GitHub
    if not all([GITHUB_TOKEN, PR_NUMBER, REPO]):
        log("‚ùå Vari√°veis de ambiente faltando. Abortando.")
        sys.exit(1)

    # Valida√ß√£o de pelo menos uma chave de LLM
    if not any([OPENAI_API_KEY, CLAUDE_API_KEY]):
        log("‚ùå Nenhuma chave de LLM informada. Use openai_api_key ou claude_api_key.")
        sys.exit(1)

    # ===============================================
    # üìã CARREGAMENTO DE CONFIGURA√á√ïES
    # ===============================================
    ignore_globs = load_ignore_patterns()      # Padr√µes glob do arquivo
    ignore_regex = compile_regex_patterns()   # Padr√µes regex da vari√°vel

    # ===============================================
    # üîç AN√ÅLISE DO PULL REQUEST
    # ===============================================
    pr = get_pull_request()
    log(f"üîç Analisando PR #{PR_NUMBER}: {pr.title}")

    # ===============================================
    # üìÅ FILTRAGEM DE ARQUIVOS MODIFICADOS
    # ===============================================
    changed_files = []
    for f in pr.get_files():
        # Limite de arquivos a analisar
        if len(changed_files) >= ANALYZE_LIMIT:
            break
            
        # Verifica se √© uma extens√£o suportada
        if not f.filename.endswith(SUPPORTED_EXTENSIONS):
            continue
            
        # Verifica se deve ser ignorado
        if should_ignore(f.filename, ignore_globs, ignore_regex):
            # log(f"üö´ Ignorado: {f.filename}")
            continue
            
        # Obt√©m conte√∫do do arquivo
        content = get_file_content(f.filename, pr.base.repo)

        # Verifica se esse cont√©udo j√° foi cacheado
        file_hash = get_file_hash(content)
        cached = load_cache(file_hash)
        if cached is not None:
            log(f"üö´ Arquivo j√° avaliado: {f.filename}")
            continue

        changed_files.append((f.filename, content))

    # ===============================================
    # ‚úÖ VALIDA√á√ÉO FINAL
    # ===============================================
    if not changed_files:
        log("‚ö†Ô∏è Nenhum arquivo eleg√≠vel encontrado ap√≥s filtros.")
        sys.exit(0)

    log(f"üì¶ {len(changed_files)} arquivos ser√£o analisados usando {'OpenAI' if OPENAI_API_KEY else 'Claude'}.")

    # ===============================================
    # ü§ñ AN√ÅLISE E GERA√á√ÉO DO RELAT√ìRIO
    # ===============================================
    full_report = ""
    for filename, content in changed_files:
        log(f"üîç Analisando: {filename}")
        analysis = analyze_code(filename, content)
        if analysis is None:
            continue
        # ===============================================
        # üí¨ PUBLICA√á√ÉO DO RELAT√ìRIO
        # ===============================================
        report = "# ü§ñ Revis√£o autom√°tica com LLM\n"+f"## üìÑ {filename}\n" + analysis
        # Trunca o relat√≥rio se exceder limite do GitHub (65.536 caracteres)
        summary = shorten_multiline(report, 60000, placeholder="\n\n... [coment√°rio truncado]")
        post_comment(pr, summary)
        full_report += report+"\n"
    
    if not full_report:
        log("‚ö†Ô∏è Nenhum report foi criado.")
